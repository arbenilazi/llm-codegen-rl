{
  "experiment_name": "mbpp_temp0.3_topp0.90",
  "seed": 42,
  "dataset": {
    "name": "mbpp",
    "hf_id": "google-research-datasets/mbpp",
    "output_dir": "assets/datasets/mbpp",
    "split_ratio": 0.9,
    "split_seed": 42
  },
  "generation": {
    "model_name": "Qwen/Qwen2.5-Coder-7B-Instruct",
    "num_candidates": 10,
    "batch_size": 32,
    "temperature": 0.3,
    "top_p": 0.9,
    "max_tokens": 512,
    "stop": "<END>",
    "dtype": "auto"
  },
  "evaluation": {
    "ks": [
      1,
      3,
      5,
      10
    ],
    "allow_code_eval": true,
    "num_procs": 16,
    "batch_size": 32
  },
  "metrics": {
    "compute_loc": true,
    "compute_tokens": true,
    "compute_cyclomatic_complexity": true,
    "compute_nesting_depth": true,
    "compute_ast_hash": true
  },
  "rl_build": {
    "out_dir": "assets/rl/mbpp",
    "n_best": 5,
    "max_pairs": 20,
    "pairs_per_winner": 2
  },
  "training": {
    "use_lora": true,
    "output_dir": "results/dpo_mbpp_lora",
    "epochs": 1,
    "batch_size": 4,
    "lr": 5e-05,
    "target_modules": [
      "q_proj",
      "k_proj",
      "v_proj",
      "o_proj"
    ],
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.05,
    "logging_steps": 50,
    "save_steps": 200,
    "eval_steps": 200
  },
  "reports": {
    "dir": "results/reports",
    "write_markdown": true
  }
}